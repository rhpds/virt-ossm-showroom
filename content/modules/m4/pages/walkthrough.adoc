# Module 4: Resilience, Scalability and Fault Aversion for VMs in a Cloud Native manner


## Task 1: Expose VMs to public requests

In the previous module you deployed and secured the _Travel Agency_ solution but there is no access to it. In a traditional environment in order to enable access to a VM from the public internet you would need to open tickets for firewall rules, loadbalancers, external DNS etc. however in the current environment networking can be defined between OpenShift and service mesh.

Openning the URL to the _Ingress Gateway_ (the mesh component used to control incoming traffic) at http://istio-ingressgateway-istio-system.{openshift_cluster_ingress_domain}/[window=_blank] does not return the _Travel Agency_ dashboard page. This is expected as we have not yet exposed any services from the mesh. 

Exposing the _Travel Agency_ dashboard to the outside world via the mesh _Ingress Gateway_ (find more extensive information in the documentation https://docs.redhat.com/en/documentation/openshift_container_platform/4.18/html-single/service_mesh/index#ossm-routing-traffic[Managing traffic in your service mesh, window=_blank] ) requires the addition of the following Custom Resources (CRs) to configure the traffic flow:

* https://istio.io/latest/docs/reference/config/networking/gateway/[`Gateway`, window=_blank]: A load balancer operating at the edge of the mesh receiving incoming or outgoing HTTP/TCP connections.

* https://istio.io/latest/docs/reference/config/networking/virtual-service/[`VirtualService`, window=_blank]: Defines traffic routing including traffic separation (multiple versions, context based etc.).

* https://istio.io/latest/docs/reference/config/networking/destination-rule/[`DestinationRule`, window=_blank]: Defines policies (loadbalancing, retries, failover, security) that apply to traffic intended for a service after routing has occurred.

Execute script {virt_ossm_workspace_repo}/{virt_ossm_workspace_project}/blob/main/lab-4/expose-control-vm.sh[expose-control-vm.sh, window=_blank] in the *Terminal*  to deploy these configurations:

[,sh,subs="attributes",role=execute]
----
cd $HOME/virt-ossm-workspace/lab-4
----

[,sh,subs="attributes",role=execute]
----
./expose-control-vm.sh {openshift_cluster_ingress_domain}
----

Refresh the URL to the _Ingress Gateway_ at http://istio-ingressgateway-istio-system.{openshift_cluster_ingress_domain}[window=_blank] and you should be served with the familiar _Travel Agency_ UI. *Congratulations your solution is public!*.

After a brief time the `Kiali` also shows the traffic flowing via the `istio-ingressgateway` towards the `control-vm`.

image::01-m4-t1-ingress-control.gif[link=self, window=blank]

## Task 2: Perform a Canary Release of a new versions of a _Virtual Machine_ application

Often you will be required to deploy and maintain multiple versions of an application to provide new features to a subset of customers. In this occasion you will be releasing *v2* of the *cars-vm* allowing *10%* of new customer requests to access the new service whilst the remainder will continue to go to *v1*. If all goes well you will increase the traffic to *v2* to *80%*.

In order to achieve this you are going to first deploy a new Virtual Machine `cars-vm-v2-a` with `version=v2` (see {virt_ossm_workspace_repo}/{virt_ossm_workspace_project}/blob/main/lab-4/cars-vm-v2-a.yaml#L38[cars-vm-v2-a.yaml,window=_blank]).

Then you need to configure the mesh traffic with a `DestinationRule` which will direct traffic destined for the `cars-vm` service to both `v1` and `v2` VMs based on their `version=v??` label (see {virt_ossm_workspace_repo}/{virt_ossm_workspace_project}/blob/main/lab-4/multipleversions-for-car-vm-in-the-mesh.sh#L30-L36[multipleversions-for-car-vm-in-the-mesh.sh,window=_blank]).

[source,yaml,subs=attributes]
----
kind: DestinationRule
apiVersion: networking.istio.io/v1alpha3
metadata:
  name: cars
  namespace: travel-agency
  labels:
    module: m4
spec:
  host: cars-vm.travel-agency.svc.cluster.local
  subsets:
    - labels:
        version: v1
      name: v1
    - labels:
        version: v2
      name: v2
----

Finally define a `VirtualService` which splits the traffic so that `90%` of the traffic reaches `v1` and `10%` to the new `cars-vm-v2-a` (which is `v2`).

[source,yaml,subs=attributes]
----
kind: VirtualService
apiVersion: networking.istio.io/v1alpha3
metadata:
  name: cars
  namespace: travel-agency
  labels:
    module: m4
spec:
  hosts:
    - cars-vm.travel-agency.svc.cluster.local
  gateways:
    - mesh
  http:
    - route:
        - destination:
            host: cars-vm.travel-agency.svc.cluster.local
            subset: v1
          weight: 90
        - destination:
            host: cars-vm.travel-agency.svc.cluster.local
            subset: v2
          weight: 10
----

NOTE: We will deliver the above via the attached terminal but you could as easily have used `Kiali` to define the configurations.

Execute the script below in the *Terminal* which delivers the above configurations:

[,sh,subs="attributes",role=execute]
----
./multipleversions-for-car-vm-in-the-mesh.sh 90 10
----

`Kiali` *Istio Config* will now list under `travel-agency` the new traffic management configurations.

image::01-m4-t1-kiali-config.png[link=self, window=blank]


Shortly after creating the traffic configuration you will start seeing the result of the traffic split in the `Kiali` console as the following animated guide also shows.

image::02-m4-t2-separate-v1-v2-traffic.gif[link=self, window=blank]

After you have verified the new version is stable go ahead and increase traffic routing for `v2` to `80%`.

[,sh,subs="attributes",role=execute]
----
./multipleversions-for-car-vm-in-the-mesh.sh 20 80
----

The config in `Kiali` has been updated (see https://kiali-istio-system.{openshift_cluster_ingress_domain}/console/namespaces/travel-agency/istio/virtualservices/cars[cars `VirtualService`, window=_blank]) and soon the graph should show `80%` traffic flowing to `v2`. 

## Task 3: Circuit Breakers

The new metrics visualisation can enable business teams to understand the level of load the solution receives and make appropriate operational decisions. In order to cater for a 50% increase in traffic to the newly released `v2` service of `cars-vm-v2` configure the solution in the mesh so that:

* you double the service capacity,
* guarantee high availability of requests to the `cars-vm` service, and
* ensure any failures do not impact end-user requests.

Service mesh in order to provide resillience to the included services implements Netflix like features. You can take advantage of the https://istio.io/latest/docs/tasks/traffic-management/circuit-breaking/[_circuit breaker_, window=_blank] feature of the mesh to achieve the required resillience in the network of VMs/containers making up the Travel Agency solution.

First, deploy an additional VM {virt_ossm_workspace_repo}/{virt_ossm_workspace_project}/blob/main/lab-4/cars-vm-v2-b.yaml[`cars-vm-v2-b`] that will also be exposed as part of `cars-vm` service (together with `cars-vm` and `cars-vm-v2-a`). It will also be labelled with version *v2* hence making requests towards *v2* hightly available between the `cars-vm-v2-a` and `cars-vm-v2-b` VMs.

Execute the following to deploy the new VM {virt_ossm_workspace_repo}/{virt_ossm_workspace_project}/blob/main/lab-4/cars-vm-v2-b.yaml[`cars-vm-v2-b`,window=_blank].

[,sh,subs="attributes",role=execute]
----
oc apply -f cars-vm-v2-b.yaml -n travel-agency
----

After deploying the new `cars-vm-v2-b` VM you should notice in `Kiali` that `cars-vm` has now 3 destinations and traffic destined for `v2` will be split almost equally at `40%` between the `v2` instances. *Congratulations* you have achieved high availability for requests on *version=v2*. It was not so difficult after all!!

image::03-m4-t3-2-v2-endpoints.png[link=self, window=blank]

Once the VM is up and running configure the https://istio.io/latest/docs/tasks/traffic-management/circuit-breaking/[_circuit breaker_, window=_blank] in the mesh so that if there is a problem on either of the 2 *version=v2* VMs the mesh will stop directing traffic to it until it has recovered. 

[,sh,subs="attributes",role=execute]
----
./circuit-breaker.sh
----

See the circuit breaker you will apply at {virt_ossm_workspace_repo}/{virt_ossm_workspace_project}/blob/main/lab-4/circuit-breaker.sh#L54-L66[circuit-breaker.sh]. In the case of a `5xx` error the mesh will eject the VM that causes the issue for `3 minutes`. Execute the following to apply the circuit breaker.

In order to protect the end user from any failures to one of the *version=v2* VMs implement now with service mesh a https://istio.io/latest/docs/tasks/traffic-management/circuit-breaking/[circuit breaker, window=_blank]. This is an important pattern used in environments with high traffic volumes and many destinations offering a loadbalance of the service (eg. Netflix) as it creates resilient microservice applications. Circuit breaking allows service mesh networking, like in an electric circuit, to monitor the healthiness of all destinations and stop using one of the *version=v2* VMs if it starts failing, hence limiting the impact of failures and latency spikes to the end user. 

Check that `Kiali` contains an updated version of the https://kiali-istio-system.{openshift_cluster_ingress_domain}/console/namespaces/travel-agency/istio/destinationrules/cars[*cars* `DestinationRule`, window=_blank] containing the circuit breaker. 

Lets force an issue in `cars-vm-v2-b` VM by going in the OpenShift console to the `cars-vm-v2-b` (see below) access the console of the VM and execute the following to stop the car application running in the VM.

[,sh,subs="attributes",role=execute]
----
systemctl --user stop cars.service 
----

image::04-m4-t3-select-vm.png[link=self, window=blank]


As a result the *version=v2* endpoint for the failing VM will be removed by the service mesh and no more requests will flow once it has detected the `5xx` failures. The exclusion lasts per configuration in the https://kiali-istio-system.{openshift_cluster_ingress_domain}/console/namespaces/travel-agency/istio/destinationrules/cars[`cars DestinationRule`, window=_blank] for `180s` upon which it will be retried and if failed it will again be excluded. If you renable the application by executing `systemctl --user start cars.service`, in the `cars-vm-v2-b` VM console, traffic for `v2` will again start being loadbalanced between the 2 VMs. All of these scenarios are showcased in the animated image below, or alterniatvely you can try them monitor in the system and `Kiali` console.

image::05-m4-t3-circuit-breaker.gif[link=self, window=blank]

*Contratulations* for helping _Travel Agency_ to make the solution as resillient as Netflix.


## Task 4: Apply business restrictions with service authorization policies

Although security features such as encryption are by default applied in the mesh other practices such as rules on what is a service's visibility and who can access them are not applied. This can have a two-fold effect. 

* Services that are bad actors deployed by 3rd party in the cluster can gain access to a sensiteve service,
* Configuration of all possible destinations in a very large cluster can make the `istio-proxy` sidecar very large causing evictions and possible cluster instability.

In order to counter these possible issues you can apply within the service mesh authorization and visibility restrictions based on that principal included in the exchanged certificate.

First apply the https://istio.io/latest/docs/ops/best-practices/security/#use-default-deny-patterns[best practice, window=_blank] `default deny all` policy. 

[,sh,subs="attributes",role=execute]
----
echo "apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-nothing
  namespace: travel-agency
spec:
  {}" | oc apply -f -

echo "apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-nothing
  namespace: travel-control
spec:
  {}" | oc apply -f -  
----

This will result in all services of the _Travel Agency_ to stop communicating with each other as they no longer have permission to do so (see `Kiali` Graph for the failures). You can confirm the effect by accessing the http://istio-ingressgateway-istio-system.{openshift_cluster_ingress_domain}/[Travel Agency Dashboard, window=_blank] which now returns `RBAC: access denied`.

Then apply fine grained `AuthorizationPolicies` which will allow communications between: 

* `istio-ingressgateway` *->* `control-vm`, 
* from services in the `travel-portal` *->* to services in `travel-agency`, and 
* all `travel-agency` services.
+
[,sh,subs="attributes",role=execute]
----
echo "apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: authpolicy-istio-ingressgateway
  namespace: istio-system
spec:
  selector:
    matchLabels:
      app: istio-ingressgateway
  rules:
    - to:
        - operation:
            paths: [\"*\"]" |oc apply -f -

echo "apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-selective-principals-travel-control
  namespace: travel-control
spec:
  action: ALLOW
  rules:
    - from:
        - source:
            principals: [\"cluster.local/ns/istio-system/sa/istio-ingressgateway-service-account\"]"|oc apply -f -

echo "apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
 name: allow-selective-principals-travel-agency
 namespace: travel-agency
spec:
 action: ALLOW
 rules:
   - from:
       - source:
           principals: [\"cluster.local/ns/travel-agency/sa/default\",\"cluster.local/ns/travel-portal/sa/default\"]" |oc apply -f -
----

In a little while you should once more gain access to the http://istio-ingressgateway-istio-system.{openshift_cluster_ingress_domain}/[Travel Agency Dashboard, window=_blank] and `Kiali` will show a restored network of communications between the solution. However, communication between `travel-control` and `travel-agency` services has been restricted as they are unnecessary.

[,sh,subs="attributes",role=execute]
----
oc -n travel-control exec $(oc -n travel-control get po -l app=control-vm|awk '{print $1}'|tail -n 1) -- curl -o - -I  travels-vm.travel-agency.svc.cluster.local:8000/travels/London |jq
----

You should receive a a response that this operation is forbidden.

[source,yaml,subs=attributes]
----
HTTP/1.1 403 Forbidden
content-length: 19
content-type: text/plain
date: Mon, 24 Mar 2025 16:10:11 GMT
server: envoy
x-envoy-upstream-service-time: 1
----

## Congratulations

You have come a long way to create a more secure and robust solution for _Travel Agency_ without modifying the original VM source code and acting upon your VMs equal to other Cloud Native components.




